{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python",
      "language": "python",
      "name": "conda-env-python-py"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.13"
    },
    "colab": {
      "name": "Final Assignment_Webscraping.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/weijhenyujhou/DS_IBM/blob/master/Python%20Project%20for%20Data%20Science/Final_Assignment_Webscraping.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bWVZUbiIV5sS"
      },
      "source": [
        "<center>\n",
        "    <img src=\"https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/Logos/organization_logo/organization_logo.png\" width=\"300\" alt=\"cognitiveclass.ai logo\"  />\n",
        "</center>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ToAKhdlhV5sS"
      },
      "source": [
        "<h1>Extracting Stock Data Using a Web Scraping</h1>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tqh-OAZeV5sT"
      },
      "source": [
        "Not all stock data is available via API in this assignment; you will use web-scraping to obtain financial data. You will be quizzed on your results.\\\n",
        "Using beautiful soup we will extract historical share data from a web-page.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "74T1zmWYV5sT"
      },
      "source": [
        "<h2>Table of Contents</h2>\n",
        "<div class=\"alert alert-block alert-info\" style=\"margin-top: 20px\">\n",
        "    <ul>\n",
        "        <li>Downloading the Webpage Using Requests Library</li>\n",
        "        <li>Parsing Webpage HTML Using BeautifulSoup</li>\n",
        "        <li>Extracting Data and Building DataFrame</li>\n",
        "    </ul>\n",
        "<p>\n",
        "    Estimated Time Needed: <strong>30 min</strong></p>\n",
        "</div>\n",
        "\n",
        "<hr>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AJC7hD0tV5sU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "782b7cc7-7938-4d01-a54f-96e7273716d3"
      },
      "source": [
        "#!pip install pandas\n",
        "#!pip install requests\n",
        "!pip install bs4\n",
        "#!pip install plotly"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: bs4 in /usr/local/lib/python3.7/dist-packages (0.0.1)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (from bs4) (4.6.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QBXl9dlTV5sU"
      },
      "source": [
        "import pandas as pd\n",
        "import requests\n",
        "from bs4 import BeautifulSoup"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VqlGNzlQV5sV"
      },
      "source": [
        "## Using Webscraping to Extract Stock Data\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "suQLoaNNV5sV"
      },
      "source": [
        "Use the `requests` library to download the webpage https://finance.yahoo.com/quote/AMZN/history?period1=1451606400\\&period2=1612137600\\&interval=1mo\\&filter=history\\&frequency=1mo\\&includeAdjustedClose=true. Save the text of the response as a variable named `html_data`.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w2Vi0k1RV5sV"
      },
      "source": [
        "url = 'https://finance.yahoo.com/quote/AMZN/history?period1=1451606400\\&period2=1612137600\\&interval=1mo\\&filter=history\\&frequency=1mo\\&includeAdjustedClose=true'\n",
        "html_data = requests.get(url).text"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ftwles8dV5sV"
      },
      "source": [
        "Parse the html data using `beautiful_soup`.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7WBx8IwsV5sW"
      },
      "source": [
        "soup = BeautifulSoup(html_data, \"html.parser\")"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e_41rtAQV5sW"
      },
      "source": [
        "<b>Question 1</b> what is the content of the title attribute:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7QxiBRqHV5sW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "176d4fcd-2b48-408a-f858-092cbd759f5d"
      },
      "source": [
        "soup.find_all('td')"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<td class=\"Fz(xs)\" colspan=\"7\" data-reactid=\"51\"><span data-reactid=\"52\">*Close price adjusted for splits.</span><span class=\"Mstart(20px)\" data-reactid=\"53\"><span data-reactid=\"54\">**Adjusted close price adjusted for both dividends and splits.</span></span></td>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ykt0jcm7V5sW"
      },
      "source": [
        "Using beautiful soup extract the table with historical share prices and store it into a dataframe named `amazon_data`. The dataframe should have columns Date, Open, High, Low, Close, Adj Close, and Volume. Fill in each variable with the correct data from the list `col`.\n",
        "\n",
        "Hint: Print the `col` list to see what data to use\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rT2xE18CV5sX"
      },
      "source": [
        "amazon_data = pd.DataFrame(columns=[\"Date\", \"Open\", \"High\", \"Low\", \"Close\", \"Volume\"])\n",
        "\n",
        "for row in soup.find(\"tbody\").find_all(\"tr\"):\n",
        "    col = row.find_all(\"td\")\n",
        "    date =col[0].text\n",
        "    Open = col[1].text\n",
        "    high = col[2].text\n",
        "    low = col[3].text\n",
        "    close = col[4].text\n",
        "    adj_close = col[5].text\n",
        "    volume = col[6].text\n",
        "    \n",
        "    amazon_data = amazon_data.append({\"Date\":date, \"Open\":Open, \"High\":high, \"Low\":low, \"Close\":close, \"Adj Close\":adj_close, \"Volume\":volume}, ignore_index=True)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KnxbXltUV5sa"
      },
      "source": [
        "Print out the first five rows of the `amazon_data` dataframe you created.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3-wevr3-V5sa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 47
        },
        "outputId": "d151191a-2eb6-4c30-9c05-0aa1811f384e"
      },
      "source": [
        "amazon_data.head()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Volume</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [Date, Open, High, Low, Close, Volume]\n",
              "Index: []"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O-vADBjdV5sa"
      },
      "source": [
        "<b>Question 2</b> What is the name of the columns of the dataframe\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CpciBaltV5sb"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MEi6zXn2V5sb"
      },
      "source": [
        "<b>Question 3</b> What is the `Open` of `Jun 01, 2019` of the dataframe?\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RAmOZe6-V5sb"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gkv317oJV5sb"
      },
      "source": [
        "<h2>About the Authors:</h2> \n",
        "\n",
        "<a href=\"https://www.linkedin.com/in/joseph-s-50398b136/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkPY0220ENSkillsNetwork23455606-2021-01-01\">Joseph Santarcangelo</a> has a PhD in Electrical Engineering, his research focused on using machine learning, signal processing, and computer vision to determine how videos impact human cognition. Joseph has been working for IBM since he completed his PhD.\n",
        "\n",
        "Azim Hirjani\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ySCQjx1-V5sb"
      },
      "source": [
        "## Change Log\n",
        "\n",
        "| Date (YYYY-MM-DD) | Version | Changed By    | Change Description        |\n",
        "| ----------------- | ------- | ------------- | ------------------------- |\n",
        "| 2020-11-10        | 1.1     | Malika Singla | Deleted the Optional part |\n",
        "| 2020-08-27        | 1.0     | Malika Singla | Added lab to GitLab       |\n",
        "\n",
        "<hr>\n",
        "\n",
        "## <h3 align=\"center\"> Â© IBM Corporation 2020. All rights reserved. <h3/>\n",
        "\n",
        "<p>\n"
      ]
    }
  ]
}